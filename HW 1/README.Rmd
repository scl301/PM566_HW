---
title: "Assignment 1: Exploratory Data Analysis"
author: "Stephanie Lee"
date: "`r Sys.Date()`"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(dplyr)
library(leaflet)
library(webshot)
library(lubridate)
```

# Main Question
Have daily concentrations of PM (particulate matter air pollution with aerodynamic diameter less than 2.5 m) decreased in California over the last 15 years (from 2004 to 2019)?

# Step 1
Given the formulated question from the assignment description, you will now conduct EDA Checklist items 2-4. First, download 2004 and 2019 data for all sites in California from the EPA Air Quality Data website. Read in the data using data.table(). For each of the two datasets, check the dimensions, headers, footers, variable names and variable types. Check for any data issues, particularly in the key variable we are analyzing. Make sure you write up a summary of all of your findings.

```{r data}
data04 <- data.table::fread("ad_viz_plotval_data_2004.csv")
data19 <- data.table::fread("ad_viz_plotval_data_2019.csv")
```

```{r}
summary(data04)
```
```{r}
summary(data19)
```
```{r}
head(data04)
```
```{r}
tail(data04)
```
```{r}
head(data19)
```

```{r}
tail(data19)
```
The 2019 data set has nearly 3 times the number of observations than the 2004 set. All 20 variables in the data are consistent between both sets. There are no missing values. PM 2.5 measurements range from -0.10 to 251in the 2004 set, and -2.2 to 120 in the 2019 set, and have means of 13.3 and 7.7 respectively. The data is organized by site name and then chronologically. Both data sets start with observations in Livermore and end with observations on Woodland-Gibson Road.

Both data sets contain negative values of PM2.5, which are impossible and need to be remedied.


# Step 2
Combine the two years of data into one data frame. Use the Date variable to create a new column for year, which will serve as an identifier. Change the names of the key variables so that they are easier to refer to in your code.

```{r}
combined <- rbind(data04, data19)
combined$Date <- as.Date(combined$Date, format="%m/%d/%Y")
combined$Year <- as.factor(format(combined$Date,'%Y'))
combined$COUNTY <- as.factor(combined$COUNTY)
combined$`Site Name` <- as.factor(combined$`Site Name`)
combined
```
```{r}
combined <- combined %>% 
  relocate(Year, .before=Date) %>% 
  rename(
    PM2.5 = `Daily Mean PM2.5 Concentration`,
    Lat = SITE_LATITUDE,
    Long = SITE_LONGITUDE)
combined
```

# Step 3
Create a basic map in leaflet() that shows the locations of the sites (make sure to use different colors for each year). Summarize the spatial distribution of the monitoring sites.

```{r color palette}
pal <- colorFactor(c('steelblue','tomato'), domain=combined$Year)
yrs <- unique(combined$Year)
```

```{r sites}
sites <- unique(combined[ , c('Year', 'Site ID', 'Site Name', 'Lat', 'Long')])
sites
```

```{r site map}
site_map <- leaflet(sites) %>% 
  # The looks of the Map
  addProviderTiles('CartoDB.Positron') %>% 
  # Some circles
  addCircles(
    lat = ~Lat, lng = ~Long,
    color = ~pal(yrs),
    opacity = .7, fillOpacity = 1, radius = 500
    ) %>%
  addLegend('bottomleft', pal = pal, values = yrs,
          title='Site Locations', opacity=1)
site_map
```
There are sites located all throughout California, with concentrations in cities along the coast in major cities, such as San Francisco, San Jose, Los Angeles, and San Diego.


# Step 4
Check for any missing or implausible values of PM in the combined dataset. Explore the proportions of each and provide a summary of any temporal patterns you see in these observations.
```{r}
summary(combined$PM2.5)
```

```{r}
nrow(combined[PM2.5 < 0])
```
```{r}
nrow(combined[is.na(PM2.5)])
```
```{r}
combined <- combined[PM2.5 > 0]
```

```{r}
combined$yday <- yday(combined$Date)

yday <- combined %>%
  group_by(yday, Year) %>%
  summarize(PM2.5_avg = mean(PM2.5))
```
```{r}
ggplot(yday, aes(x=PM2.5_avg, fill=Year)) +
  geom_histogram(binwidth = 0.5, position='dodge') +
  theme(legend.position='right')
```
238 of the total 72389 observations had an implausible negative PM 2.5 value, comprising 0.4% of total measurements. PM 2.5 measurements skewed left with the median at 7.20 with a max value of 251 (this max measurement is valid, as California fires can cause this spike in air quality). 



# Step 5
Explore the main question of interest at three different spatial levels. Create exploratory plots (e.g. boxplots, histograms, line plots) and summary statistics that best suit each level of data. Be sure to write up explanations of what you observe in these data.

## State
```{r}
state_level <- combined %>%
  group_by(yday,Year) %>%
  summarize(PM2.5_avg = mean(PM2.5))
```


```{r}
state_plot <- ggplot(state_level, aes(x=yday, y=PM2.5_avg, color = Year)) +
  geom_line(aes(fill=Year)) +
  labs(title="Temporal Patterns of Average PM 2.5 For All Sites",
        x ="Day of the Year", y = "PM2.5 (ug/m3)",
        color = "Year")

state_plot
```
Compared to 2019, the PM 2.5 levels of 2004 visually shows to be overall higher throughout the year. Especially towards the beginning and ending months.

## County

```{r}
county_level <- combined %>%
  group_by(COUNTY, Year) %>%
  summarize(PM2.5_avg = mean(PM2.5))

county_level
```

```{r}
county_bar <- ggplot(county_level, aes(x=PM2.5_avg, y=COUNTY, fill=Year)) +
  geom_bar(stat = 'identity', alpha=0.5) +
  theme(legend.position="right")

county_bar
```
The same pattern is shown between PM 2.5 averages by county, where 2004 PM 2.5 levels are much higher than in 2019.


## Site in Los Angeles
```{r}
sites_la <- combined[COUNTY=="Los Angeles"] %>%
  group_by(`Site Name`,Year)

sites_la
```

```{r fig.height=15, fig_width=5}

sites_violin <- ggplot(sites_la, aes(x=PM2.5, y=`Site Name`, fill=Year, color=Year)) +
  geom_violin(position=position_dodge(1)) +
  theme(legend.position="right")

sites_violin
```

